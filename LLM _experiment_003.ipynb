{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# Classificação de Demandas do Fala.BR\n","---\n","## Projeto do Bootcamp Machine Learning (Anderson Monteiro e Léo Maranhão de Mello)\n"],"metadata":{"id":"J99vH9lBTiSQ"}},{"cell_type":"markdown","source":["### Problema\n","O problema consiste em classificar as demandas recebidas pela Ouvidoria da SUSEP, por meio do sistema Fala.BR."],"metadata":{"id":"z2DgYs7RtQC_"}},{"cell_type":"markdown","source":["### Solução de IA\n","Para fins de comparação com a solução em ML, utilizaremos uma solução em LLM, além de alguns testes sobre aumento de dados (data aumengtation). A LLM escolhida foi a BERTimbau."],"metadata":{"id":"24RzTsRBtOdw"}},{"cell_type":"code","source":["# general imports\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Sklearn imports\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","\n","# others\n","import torch\n","from google.colab import drive\n","%pip install odfpy"],"metadata":{"id":"1z9Cfhasu9HT","executionInfo":{"status":"ok","timestamp":1729704787667,"user_tz":180,"elapsed":3776,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"33cb5c90-e51e-43b8-c9e2-a93447bf54dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: odfpy in /usr/local/lib/python3.10/dist-packages (1.4.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from odfpy) (0.7.1)\n"]}]},{"cell_type":"markdown","source":["### Carga dos Dados"],"metadata":{"id":"JFhSx-msxJjD"}},{"cell_type":"code","source":["# monta o goole drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eR3Q3Q2Bvv-0","executionInfo":{"status":"ok","timestamp":1729704793477,"user_tz":180,"elapsed":2802,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"ebb38f87-6591-48ee-a101-00f061b3335b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Carregar dados da planilha\n","df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/Projeto IA - Amostra Anonimizada - Demandas úteis da ouvidoria 2023.ods\", engine=\"odf\")\n","\n","df['Categoria'] = df['Categoria'].replace(['Capitalização', 'Seguro Compreensivo', 'Consulta Técnica', 'Seguro Fiança Locatícia', 'Seguro de Transportes', 'Seguro de Responsabilidade', 'Seguro de Crédito Interno', 'Seguro Rural', 'Seguro Garantia Estendida'], 'Outros')\n","\n","# Inicializa BERT\n","\n","model_name = \"neuralmind/bert-base-portuguese-cased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=9)\n","\n","# Substituição das categorias de y_train e y_test por dados numéricos\n","y_mapping = {\n","    'Cadastro': 0,\n","    'Seguro de Pessoas': 1,\n","    'Não identificada': 2,\n","    'Seguro de Automoveis': 3,\n","    'Previdência Complementar Aberta': 4,\n","    'Seguro de Danos': 5,\n","    'Outros': 6,\n","    'Seguro Garantia': 7,\n","    'DPVAT/SPVAT': 8\n","}\n","\n","# Defina X e y\n","X = df['Demanda']\n","y = df['Categoria'].apply(lambda x: y_mapping[x])\n","\n","# Dividir os dados em conjuntos de treino e teste\n","X_train_antes, X_test, y_train_antes, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Inclusão dos dados de treino gerados pelo ChatGPT\n","\n","X_train_depois = X_train_antes\n","X_train_depois = pd.DataFrame(X_train_depois, columns=['Demanda'])\n","y_train_antes = pd.DataFrame(y_train_antes, columns=['Categoria'])\n","X_train_depois['Categoria'] = y_train_antes['Categoria']\n","X_train_depois = X_train_depois[X_train_depois['Categoria'] == 0]\n","\n","X_train_depois.loc[:, 'Categoria']= 'Cadastro' # Coloca a coluna categoria como texto\n","\n","# Adiciona dados auto\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_auto.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados dpvat\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_dpvat.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados garantia\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_garantia.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados não identificadas\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_nao_identificadas.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados outros\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_outros.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados pessoas\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_pessoas.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados prev privada\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_previdencia_privada.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados danos\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_seguro_danos.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Substituição das categorias de y_train por dados numéricos\n","y_mapping = {\n","    'Cadastro': 0,\n","    'Seguro de Pessoas': 1,\n","    'Não identificada': 2,\n","    'Seguro de Automoveis': 3,\n","    'Previdência Complementar Aberta': 4,\n","    'Seguro de Danos': 5,\n","    'Outros': 6,\n","    'Seguro Garantia': 7,\n","    'DPVAT/SPVAT': 8\n","}\n","\n","# Defina X e y\n","X_train = X_train_depois['Demanda']\n","y_train = X_train_depois['Categoria'].apply(lambda x: y_mapping[x])\n","\n","#X_train = pd.DataFrame(X_train, columns=['Demanda'])\n","#X_test = pd.DataFrame(X_test, columns=['Demanda'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQZEMQz7UTGU","executionInfo":{"status":"ok","timestamp":1729706200072,"user_tz":180,"elapsed":7706,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"b8277548-dc86-4022-c4f3-dadff07a7371"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Separa os arquivos de treino em treino e validação\n","X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n","\n","train_texts = X_train_train.tolist()\n","val_texts = X_train_val.tolist()"],"metadata":{"id":"QK82E0D0N7c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transforma os valores de texto em  sequencias de numeros\n","train_encodings = tokenizer(train_texts, max_length=512, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, max_length=512, truncation=True, padding=True)\n"],"metadata":{"id":"Dsjn9sJvQz0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TicketDataset(torch.utils.data.Dataset):\n","# Classe básica para pegar o par texto x target e mandar para o pytorch\n","# Pytorch é necessário aqui como um ferramental para pegar os tokens e treinar\n","# no LLM\n","    def __init__(self, encodings, labels): # inicializa os parametros\n","        self.encodings = encodings\n","        self.labels = labels\n","    def __len__(self): # retorna quantidade de labels quando chamada por len()\n","        return len(self.labels)\n","    def __getitem__(self, idx): # retorna um item quando chamada por []\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item"],"metadata":{"id":"3-alYQXjUBlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cria os datasets\n","train_dataset = TicketDataset(train_encodings, y_train_train.tolist())\n","val_dataset = TicketDataset(val_encodings, y_train_val.tolist())"],"metadata":{"id":"iXVXoOVHULGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configuracoes de treinamento\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=64,   # batch size for evaluation\n","    warmup_steps=500,                # aumenta a taxa de aprendizado a cada step\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    run_name = \"bert-base-portuguese-cased\"\n",")\n","\n","# simplifica o loop de treinamento (aquela parte do loop)\n","trainer = Trainer(\n","    model=model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset             # evaluation dataset\n",")"],"metadata":{"id":"11Q5nfHhJTav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"kqMfF2Y5N6Wz","executionInfo":{"status":"ok","timestamp":1729708596792,"user_tz":180,"elapsed":816414,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"4a3f3add-3926-4b2e-c072-debae57b0123"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [504/504 13:33, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.002500</td>\n","      <td>0.434433</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.050900</td>\n","      <td>0.513465</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.089700</td>\n","      <td>0.788430</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=504, training_loss=0.016265731508148803, metrics={'train_runtime': 815.1756, 'train_samples_per_second': 9.837, 'train_steps_per_second': 0.618, 'total_flos': 2110020159734784.0, 'train_loss': 0.016265731508148803, 'epoch': 3.0})"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["test_texts = X_test.tolist()\n","test_encodings = tokenizer(test_texts, max_length=512, truncation=True, padding=True)\n","test_dataset = TicketDataset(test_encodings, y_test.tolist())\n","preds_output = trainer.predict(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"SpDQeUamOOuA","executionInfo":{"status":"ok","timestamp":1729708819679,"user_tz":180,"elapsed":10588,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"7d0361b1-2276-41d7-b314-062636199be5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"cell_type":"code","source":["preds = torch.argmax(torch.tensor(preds_output.predictions), dim=1)\n","\n","y_pred = preds.numpy()\n","y_true = y_test.to_numpy()\n","\n","print(\"Relatorio de Classificacao:\\n\", classification_report(y_true, y_pred, target_names=list(y_mapping.keys())))\n","print(\"Acuracia:\", accuracy_score(y_true, y_pred))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJzOCjiAVCfp","executionInfo":{"status":"ok","timestamp":1729708993253,"user_tz":180,"elapsed":645,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"eba7fee0-8d5b-49e1-b9ff-ba2051b4c7b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Relatorio de Classificacao:\n","                                  precision    recall  f1-score   support\n","\n","                       Cadastro       0.98      0.91      0.95        94\n","              Seguro de Pessoas       0.95      0.85      0.90        72\n","               Não identificada       0.86      0.70      0.77        46\n","           Seguro de Automoveis       0.86      1.00      0.92        36\n","Previdência Complementar Aberta       0.94      1.00      0.97        16\n","                Seguro de Danos       0.63      0.92      0.75        13\n","                         Outros       0.82      0.82      0.82        11\n","                Seguro Garantia       0.45      0.82      0.58        11\n","                    DPVAT/SPVAT       0.88      1.00      0.93         7\n","\n","                       accuracy                           0.88       306\n","                      macro avg       0.82      0.89      0.84       306\n","                   weighted avg       0.90      0.88      0.88       306\n","\n","Acuracia: 0.8758169934640523\n"]}]}]}