{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# Classifica√ß√£o de Demandas do Fala.BR\n","---\n","## Projeto do Bootcamp Machine Learning (Anderson Monteiro e L√©o Maranh√£o de Mello)\n"],"metadata":{"id":"J99vH9lBTiSQ"}},{"cell_type":"markdown","source":["### Problema\n","O problema consiste em classificar as demandas recebidas pela Ouvidoria da SUSEP, por meio do sistema Fala.BR."],"metadata":{"id":"z2DgYs7RtQC_"}},{"cell_type":"markdown","source":["### Solu√ß√£o de IA\n","Para fins de compara√ß√£o com a solu√ß√£o em ML, utilizaremos uma solu√ß√£o em LLM, al√©m de alguns testes sobre aumento de dados (data aumengtation). A LLM escolhida foi a BERTimbau."],"metadata":{"id":"24RzTsRBtOdw"}},{"cell_type":"code","source":["# general imports\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Sklearn imports\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","\n","# others\n","import torch\n","from google.colab import drive\n","%pip install odfpy"],"metadata":{"id":"1z9Cfhasu9HT","executionInfo":{"status":"ok","timestamp":1729704787667,"user_tz":180,"elapsed":3776,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"33cb5c90-e51e-43b8-c9e2-a93447bf54dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: odfpy in /usr/local/lib/python3.10/dist-packages (1.4.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from odfpy) (0.7.1)\n"]}]},{"cell_type":"markdown","source":["### Carga dos Dados"],"metadata":{"id":"JFhSx-msxJjD"}},{"cell_type":"code","source":["# monta o goole drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eR3Q3Q2Bvv-0","executionInfo":{"status":"ok","timestamp":1729704793477,"user_tz":180,"elapsed":2802,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"ebb38f87-6591-48ee-a101-00f061b3335b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Carregar dados da planilha\n","df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/Projeto IA - Amostra Anonimizada - Demandas uÃÅteis da ouvidoria 2023.ods\", engine=\"odf\")\n","\n","df['Categoria'] = df['Categoria'].replace(['Capitaliza√ß√£o', 'Seguro Compreensivo', 'Consulta T√©cnica', 'Seguro Fian√ßa Locat√≠cia', 'Seguro de Transportes', 'Seguro de Responsabilidade', 'Seguro de Cr√©dito Interno', 'Seguro Rural', 'Seguro Garantia Estendida'], 'Outros')\n","\n","# Inicializa BERT\n","\n","model_name = \"neuralmind/bert-base-portuguese-cased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=9)\n","\n","# Substitui√ß√£o das categorias de y_train e y_test por dados num√©ricos\n","y_mapping = {\n","    'Cadastro': 0,\n","    'Seguro de Pessoas': 1,\n","    'N√£o identificada': 2,\n","    'Seguro de Automoveis': 3,\n","    'Previd√™ncia Complementar Aberta': 4,\n","    'Seguro de Danos': 5,\n","    'Outros': 6,\n","    'Seguro Garantia': 7,\n","    'DPVAT/SPVAT': 8\n","}\n","\n","# Defina X e y\n","X = df['Demanda']\n","y = df['Categoria'].apply(lambda x: y_mapping[x])\n","\n","# Dividir os dados em conjuntos de treino e teste\n","X_train_antes, X_test, y_train_antes, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Inclus√£o dos dados de treino gerados pelo ChatGPT\n","\n","X_train_depois = X_train_antes\n","X_train_depois = pd.DataFrame(X_train_depois, columns=['Demanda'])\n","y_train_antes = pd.DataFrame(y_train_antes, columns=['Categoria'])\n","X_train_depois['Categoria'] = y_train_antes['Categoria']\n","X_train_depois = X_train_depois[X_train_depois['Categoria'] == 0]\n","\n","X_train_depois.loc[:, 'Categoria']= 'Cadastro' # Coloca a coluna categoria como texto\n","\n","# Adiciona dados auto\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_auto.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados dpvat\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_dpvat.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados garantia\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_garantia.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados n√£o identificadas\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_nao_identificadas.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados outros\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_outros.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados pessoas\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_pessoas.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados prev privada\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_previdencia_privada.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Adiciona dados danos\n","df_treino_novo = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/bootcamp/dados/todas_demandas_seguro_danos.ods\", engine=\"odf\")\n","X_train_depois = pd.concat([X_train_depois, df_treino_novo])\n","\n","# Substitui√ß√£o das categorias de y_train por dados num√©ricos\n","y_mapping = {\n","    'Cadastro': 0,\n","    'Seguro de Pessoas': 1,\n","    'N√£o identificada': 2,\n","    'Seguro de Automoveis': 3,\n","    'Previd√™ncia Complementar Aberta': 4,\n","    'Seguro de Danos': 5,\n","    'Outros': 6,\n","    'Seguro Garantia': 7,\n","    'DPVAT/SPVAT': 8\n","}\n","\n","# Defina X e y\n","X_train = X_train_depois['Demanda']\n","y_train = X_train_depois['Categoria'].apply(lambda x: y_mapping[x])\n","\n","#X_train = pd.DataFrame(X_train, columns=['Demanda'])\n","#X_test = pd.DataFrame(X_test, columns=['Demanda'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQZEMQz7UTGU","executionInfo":{"status":"ok","timestamp":1729706200072,"user_tz":180,"elapsed":7706,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"b8277548-dc86-4022-c4f3-dadff07a7371"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Separa os arquivos de treino em treino e valida√ß√£o\n","X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n","\n","train_texts = X_train_train.tolist()\n","val_texts = X_train_val.tolist()"],"metadata":{"id":"QK82E0D0N7c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transforma os valores de texto em  sequencias de numeros\n","train_encodings = tokenizer(train_texts, max_length=512, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, max_length=512, truncation=True, padding=True)\n"],"metadata":{"id":"Dsjn9sJvQz0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TicketDataset(torch.utils.data.Dataset):\n","# Classe b√°sica para pegar o par texto x target e mandar para o pytorch\n","# Pytorch √© necess√°rio aqui como um ferramental para pegar os tokens e treinar\n","# no LLM\n","    def __init__(self, encodings, labels): # inicializa os parametros\n","        self.encodings = encodings\n","        self.labels = labels\n","    def __len__(self): # retorna quantidade de labels quando chamada por len()\n","        return len(self.labels)\n","    def __getitem__(self, idx): # retorna um item quando chamada por []\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item"],"metadata":{"id":"3-alYQXjUBlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cria os datasets\n","train_dataset = TicketDataset(train_encodings, y_train_train.tolist())\n","val_dataset = TicketDataset(val_encodings, y_train_val.tolist())"],"metadata":{"id":"iXVXoOVHULGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configuracoes de treinamento\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=64,   # batch size for evaluation\n","    warmup_steps=500,                # aumenta a taxa de aprendizado a cada step\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    run_name = \"bert-base-portuguese-cased\"\n",")\n","\n","# simplifica o loop de treinamento (aquela parte do loop)\n","trainer = Trainer(\n","    model=model,                         # the instantiated ü§ó Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset             # evaluation dataset\n",")"],"metadata":{"id":"11Q5nfHhJTav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"kqMfF2Y5N6Wz","executionInfo":{"status":"ok","timestamp":1729708596792,"user_tz":180,"elapsed":816414,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"4a3f3add-3926-4b2e-c072-debae57b0123"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [504/504 13:33, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.002500</td>\n","      <td>0.434433</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.050900</td>\n","      <td>0.513465</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.089700</td>\n","      <td>0.788430</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=504, training_loss=0.016265731508148803, metrics={'train_runtime': 815.1756, 'train_samples_per_second': 9.837, 'train_steps_per_second': 0.618, 'total_flos': 2110020159734784.0, 'train_loss': 0.016265731508148803, 'epoch': 3.0})"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["test_texts = X_test.tolist()\n","test_encodings = tokenizer(test_texts, max_length=512, truncation=True, padding=True)\n","test_dataset = TicketDataset(test_encodings, y_test.tolist())\n","preds_output = trainer.predict(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"SpDQeUamOOuA","executionInfo":{"status":"ok","timestamp":1729708819679,"user_tz":180,"elapsed":10588,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"7d0361b1-2276-41d7-b314-062636199be5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"cell_type":"code","source":["preds = torch.argmax(torch.tensor(preds_output.predictions), dim=1)\n","\n","y_pred = preds.numpy()\n","y_true = y_test.to_numpy()\n","\n","print(\"Relatorio de Classificacao:\\n\", classification_report(y_true, y_pred, target_names=list(y_mapping.keys())))\n","print(\"Acuracia:\", accuracy_score(y_true, y_pred))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJzOCjiAVCfp","executionInfo":{"status":"ok","timestamp":1729708993253,"user_tz":180,"elapsed":645,"user":{"displayName":"Leo","userId":"13479278840004145086"}},"outputId":"eba7fee0-8d5b-49e1-b9ff-ba2051b4c7b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Relatorio de Classificacao:\n","                                  precision    recall  f1-score   support\n","\n","                       Cadastro       0.98      0.91      0.95        94\n","              Seguro de Pessoas       0.95      0.85      0.90        72\n","               N√£o identificada       0.86      0.70      0.77        46\n","           Seguro de Automoveis       0.86      1.00      0.92        36\n","Previd√™ncia Complementar Aberta       0.94      1.00      0.97        16\n","                Seguro de Danos       0.63      0.92      0.75        13\n","                         Outros       0.82      0.82      0.82        11\n","                Seguro Garantia       0.45      0.82      0.58        11\n","                    DPVAT/SPVAT       0.88      1.00      0.93         7\n","\n","                       accuracy                           0.88       306\n","                      macro avg       0.82      0.89      0.84       306\n","                   weighted avg       0.90      0.88      0.88       306\n","\n","Acuracia: 0.8758169934640523\n"]}]}]}